回答问题注意大局观,整体的大模块,架构讲清楚,先整体后细节

dag工作流,任务场景,如何实现的,调度流程(dag可能不是重点,重点在特征相关的工作)
(机器学习任务主要分离线和在线部分,dag在我们的场景是处理**离线**部分的, 在线部分主要由另一个rerank服务处理)

-  dag 也就是 有向无环图,用来构建一种有依赖关系的执行工作流
-  我们的场景主要是通过dag把机器学习训练的离线过程以一种工作流的方式连接起来
   一个简单的流程是: 数据集, 画像值获取 ,特征转化 ,切分数据集 ,训练 ,预测,部署
   我们的系统除了包含官方提供的一些重要基础组件还支持用户自定义他们的组件实现定制化需求
-  (大体思路)一个dag流图对应一个job
   dag里的多个组件(也就是节点)对应多个task
   task之间存在依赖关系
   task由 ComponentRunner 具体触发
   执行时,系统根据component的名字还有属性构建runner(dag里只记录了名字和属性)

为什么要用quartz?
用户经常提交定时任务,所以需要频繁变动调整cron表达式

画像组件,特征组件,特征库具体是做什么的,整体的特征平台架构?
-  假期期间,我大致看了下美团机器学习平台实践这本书,还有美团技术团队特征平台的那篇博客,
   我们的架构稍有区别,但是大体的数据处理流程是类似的.
   首先,我需要说一下在定义上的一点区别,方便后续的沟通
   画像其实含义没有变化,就是对事物的属性描述
   特征有两层含义:
      -  一种是定义为一种转化关系,这种转化关系就是画像到模型输入的一种关系转化
         (通过dsl来描述,美团应该也有在用类似的)
      -  另一种就是模型的输入了
   所以我们的特征平台主要是类似一种画像到特征的映射配置关系
   而美团的特征平台比较类似于我们的画像平台
   
   这部分也分离线和在线数据两个部分:
   -  首先是使用spark将hdfs上的数据写到kafka和WAL(公司的一种中间存储中间件,结构类似于Hbase底层的Hfile结构)
      -  在线kv存储拉取kafka里的数据,另外对于事实写请求,除了会写入kv另外还会写入到WAL(保证离线的一致性)
   -  而wal后面的链路就和离线有关了分两路,一个是写入到hbase(用于在线kv查不到的时候点查),一个是写到delta lake
      后续写入dt表(用于离线训练)和年表(用于分群业务)
   
上面呢基本就介绍了画像的离线和在线数据源了

但是目前我们还有一路更优的离线画像源
(主要是通过实时曝光的日志流数据和点击流做join生成的数据,落盘,这里的数据就已经包含曝光对象的画像信息,还有用户信息了)
在此基础上算法标注正负样本就可以用来进行离线训练了,这个数据是按小时更新,比dt的快照表数据更加实时.

   训练时的样本数据有算法同学自己生产,平台提供xql组件,让用户可以通过写sql的方式动态调整数据,join操作等
   
   画像组件的作用就是基于用户提供的样本数据,将对应样本中各种domian类型的数据通过id join画像表得到用户需要的画像,生成一张大宽表
   这些画像作为特征组件的输入,需要一些配置,主要是告诉画像组件样本中哪一列是哪个domain的关联id.
   
   特征组件的作用就是基于上面的输入,还有用户在平台上配置的特征转化关系,将这个大宽表生成用户选择的所有特征值
   (也是张表,考虑到数据的稀疏性问题还有数据压缩问题,我们在转化过程中把所有的特征通过编码的方式放到了同一列),
   训练前会解码模型的输入
   
   特征库就是一个特征配置平台,可以配置各种类型的特征(id类型,enum类型,onehot,交叉等),
   也可以做特征探索,生成数据的一些分布信息给用户参考配置特征
   
为什么要做上云迁移改造?
   个人理解是一个政治任务, 上云对我们平台没有任何好处,只是增加了工作量,还有比较大的风险,
   个人而言的话,可以梳理一下部门服务的整体架构,熟悉大数据组件的构建依赖关系,配置等.

项目中遇到的最大难点是什么?怎么解决
   工作中肯定是会遇到很多问题,当时会觉得比较难,但是解决后也觉得没什么,我觉得比较困难的问题主要是对于某些需求,
   如何基于现有的代码框架去实现,不是对现有的代码修修补补,而是基于代码框架做一个标准化的方案实现,也就是考虑后续的可维护性.
   我觉得这个是一个难点也是一直需要追求和提升的点.
   
   业务上的话,比较有印象的是对于listwise混排的一个支持,画像组件需要绑定画像组和画像列,对于listwise的情况,
   排序的对象是多个(专辑,声音,书单等),也就是不统一,也可能有**多个**, 对于多个相同类型这种场景,比如一条样本里存在多个专辑id
   现有一个domian一个关联id的情况就失效了,基本无法实现用户的需求.解决方式主要还是多与算法沟通了解使用场景,结合当前的工程实现去设计
   方案,最终是通过构建虚拟画像的方式实现,用户不走画像组件,通过xql组件自己构建特征的输入列,单独为此场景设计了对应的特征转化组件,等

实时训练平台
   实时训练平台在数据源上,让用户自行的配置,包括批数据hive表和流数据kafka topic, 
   可以配置提交spark任务,flink任务会生成相关的一些配置,主逻辑已经写好再公司的flink平台注册好了,
   用户只需要基于配置自行去公司的flink任务平台提交
   优化部分:多实例可以保证服务的可用性,但是对于调度任务来说,多个实例不可让所有的实例都执行调度,这样同一个任务会调度多次
         但是单实例部署,如果存在宕机的话分险是比较高的,所以这里设计了分布式锁来保证单实例调度,多实例部署
   
特征配置化
   这部分主要是考虑如何提高特征转化过程的速率问题

标准化组件服务
   这里需要和dag离线调度平台一起解释了. 

   离线部分简单来说  由dag后台,任务调度,
   spark提交服务, 训练组件提交服务,标准组件配置服务 构成

   dag后台主要是用于 构建dag,连线之类的操作
   
   任务调度服务是调度任务执行 , 具体执行

   当执行到标准化组件时 会 和标准化组件配置服务交互,提交任务,查询任务状态,获取日志信息等,
   
   spark服务,训练组件服务,会轮询 准化组件配置服务 获取任务,写会任务状态,日志路径等


线上推理部分:
   rerank服务 加载模型信息还有 画像,特征配置信息 ,基于输入,先去画像在线服务拉取画像信息,然后去特征引擎服务做特征转化 
   然后调用在推理服务上部署的tf-serving 获取结果返回,






















   